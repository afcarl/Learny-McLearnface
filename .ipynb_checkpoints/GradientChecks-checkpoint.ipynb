{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Gradient Checks\n",
    "\n",
    "Here, we use numerical gradient checking to verify the backpropagation correctness of all layers in the Layers folder.  We should expect to see very small nonzero values for error, as the checking process approximates the gradient numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from NeuralNetwork import *\n",
    "from Utils.NumericalGradient import *\n",
    "\n",
    "from Layers.SoftmaxLossLayer import *\n",
    "from Layers.AffineLayer import *\n",
    "from Layers.ReLULayer import *\n",
    "from Layers.SigmoidLayer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Layer\n",
    "Layers/AffineLayer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3520b06e8ecd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdW_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0maffine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdb_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0maffine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maffine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Affine dx error: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelative_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdx_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Affine dW error: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelative_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "affine = AffineLayer(30, 10, 1e-2)\n",
    "test_input = np.random.randn(50, 30)\n",
    "dout = np.random.randn(50, 10)\n",
    "_ = affine.forward(test_input)\n",
    "dx_num = numerical_gradient_layer(lambda x : affine.forward(x, affine.W, affine.b), test_input, dout)\n",
    "dW_num = numerical_gradient_layer(lambda w : affine.forward(test_input, w, affine.b), affine.W, dout)\n",
    "db_num = numerical_gradient_layer(lambda b : affine.forward(test_input, affine.W, b), affine.b, dout)\n",
    "dx = affine.backward(dout)\n",
    "print 'Affine dx error: ', np.max(relative_error(dx, dx_num))\n",
    "print 'Affine dW error: ', np.max(relative_error(affine.dW, dW_num))\n",
    "print 'Affine db error: ', np.max(relative_error(affine.db, db_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU (Rectified Linear Unit) Layer\n",
    "Layers/ReLULayer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU dx error:  3.27563009974e-12\n"
     ]
    }
   ],
   "source": [
    "relu = ReLULayer(10)\n",
    "test_input = np.random.randn(50, 10)\n",
    "dout = np.random.randn(50, 10)\n",
    "_ = relu.forward(test_input)\n",
    "dx_num = numerical_gradient_layer(lambda x : relu.forward(x), test_input, dout)\n",
    "dx = relu.backward(dout)\n",
    "print 'ReLU dx error: ', np.max(relative_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Layer\n",
    "Layers/SigmoidLayer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid dx error:  5.69203688508e-11\n"
     ]
    }
   ],
   "source": [
    "sigmoid = SigmoidLayer(10)\n",
    "test_input = np.random.randn(50, 10)\n",
    "dout = np.random.randn(50, 10)\n",
    "_ = sigmoid.forward(test_input)\n",
    "dx_num = numerical_gradient_layer(lambda x : sigmoid.forward(x), test_input, dout)\n",
    "dx = sigmoid.backward(dout)\n",
    "print 'Sigmoid dx error: ', np.max(relative_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Loss Layer\n",
    "Layers/SoftmaxLossLayer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax backprop error:  1.86304637047e-07\n"
     ]
    }
   ],
   "source": [
    "softmax = SoftmaxLossLayer(10)\n",
    "test_scores = np.random.randn(50, 10)\n",
    "test_classes = np.random.randint(1, 10, 50)\n",
    "_, dx = softmax.loss(test_scores, test_classes)\n",
    "dx_num = numerical_gradient(lambda x : softmax.loss(x, test_classes)[0], test_scores)\n",
    "print 'Softmax backprop error: ', np.max(relative_error(dx, dx_num))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
